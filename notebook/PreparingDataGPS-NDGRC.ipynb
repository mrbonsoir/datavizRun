{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8b449a7-ff59-4b54-bd7d-4f3ec4495179",
   "metadata": {},
   "source": [
    "# Collecting and preparing data before analysis\n",
    "\n",
    "In that notebook I'm loading data from one run club.\n",
    "\n",
    "Data are being collected as usual and store into data folder.\n",
    "\n",
    "The fodler contains *gpx* files that need to be processed such that I have Pandas Dataframe to work with after to create datavisualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffe50e3-2c01-4baa-adf1-050701a7d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      54\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/gpx/NDGRC*gpx | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dccd6-f394-49c8-bb3d-1f6144042a60",
   "metadata": {},
   "source": [
    "### Import a few modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff46dae-c8ba-4ace-95a1-7dcd975a65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance\n",
    "import glob\n",
    "import os\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd53f1f-60b0-43a2-97c4-6c2dd215bb98",
   "metadata": {},
   "source": [
    "below I'm loading my module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a1adc7-a5af-4dad-84da-58f88f1d4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../my_modules\")\n",
    "import toolToReadGPX as ttrgpx\n",
    "\n",
    "path_data     = \"../data/\"\n",
    "path_data_csv = \"../data/csv/\"\n",
    "run_club_name = \"NDGRC\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68fe64-2e79-48e3-a7d9-bfe1d62a3534",
   "metadata": {},
   "source": [
    "# Rename files\n",
    "\n",
    "I want all files to be as follows **RunRite_year_month_day.gpx**.\n",
    "\n",
    "I will:\n",
    "+ list the files\n",
    "+ lower case all the files\n",
    "+ re-write **RunRite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac263a81-c3d4-4e89-af30-83c0ab236b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "# list and rename the files\n",
    "ll = glob.glob(path_data+\"gpx/\"+run_club_name+\"*.gpx\")\n",
    "ll.sort()\n",
    "for c, l in enumerate(ll):\n",
    "    head_tail = os.path.split(ll[c])\n",
    "    dst_tail  = head_tail[1].lower()\n",
    "    dst_head_tail = head_tail[0]+\"/\"+run_club_name+\"_\"+dst_tail[-14:]\n",
    "    os.rename(ll[c], dst_head_tail)\n",
    "    \n",
    "print(len(ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a652ba-206f-4364-a259-764b74df353f",
   "metadata": {},
   "source": [
    "## Format data in pandas DataFrame\n",
    "\n",
    "Once I found the right Python libraries, I have created some tools (ie my own modules) to load those .gpx files, to get some information about them and to save them as pandas DataFrame. The idea is to no have to re-load all my source data files each time I want to do something with them.\n",
    "\n",
    "I'm using:\n",
    "+ https://pypi.org/project/gpxpy/\n",
    "+ https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6afc6e-13c3-4094-a29b-058a18cd412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 54 files to process.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ttrgpx)\n",
    "\n",
    "# Select gpx file\n",
    "list_all_files_gpx = glob.glob(path_data+\"/gpx/\"+run_club_name+\"*.gpx\")\n",
    "list_all_files_gpx.sort()\n",
    "print(\"There is {0:1.0f} files to process.\".format(len(list_all_files_gpx)))\n",
    "\n",
    "#new_list = [expression for member in iterable]\n",
    "list_all_files_as_df = [ttrgpx.fun_gpx2pd(single_gpx) for single_gpx in list_all_files_gpx]\n",
    "\n",
    "# get number of run\n",
    "nb_run = len(list_all_files_as_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "566f924c-dc24-4c29-8387-4a8e9e355a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance per run for all the gpx paths listed: 8.64km.\n"
     ]
    }
   ],
   "source": [
    "# get average distance for this year\n",
    "list_cumulative_distance = [x.iloc[-1,4] for x in list_all_files_as_df]\n",
    "average_run_distance     = sum(list_cumulative_distance) / (1000*len(list_cumulative_distance))\n",
    "\n",
    "print(\"Average distance per run for all the gpx paths listed: {0:1.2f}km.\".format(average_run_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4a206-9ff5-49c2-9649-c2863abaa19c",
   "metadata": {},
   "source": [
    "# Reduce data size\n",
    "\n",
    "Here I will reduce the data size as I don't need so many points (eg here more than 1000) and will reduce the length to **x** points per gpx points.\n",
    "\n",
    "And I will save the downsample path as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6854bb1-d55c-41e4-b3d5-ae8fd1e9688b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>distance</th>\n",
       "      <th>cumulative_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.471887</td>\n",
       "      <td>-73.615784</td>\n",
       "      <td>60.395000</td>\n",
       "      <td>2.785459</td>\n",
       "      <td>4641.512253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>12.083419</td>\n",
       "      <td>0.944495</td>\n",
       "      <td>2664.131028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>45.464944</td>\n",
       "      <td>-73.635002</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.468345</td>\n",
       "      <td>-73.625974</td>\n",
       "      <td>51.750000</td>\n",
       "      <td>2.639801</td>\n",
       "      <td>2340.691893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.472427</td>\n",
       "      <td>-73.616678</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>3.012348</td>\n",
       "      <td>4694.263953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.475249</td>\n",
       "      <td>-73.605759</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.251237</td>\n",
       "      <td>6979.636979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.477693</td>\n",
       "      <td>-73.595871</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>6.635520</td>\n",
       "      <td>9006.744506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         latitude   longitude   elevation    distance  cumulative_distance\n",
       "count  200.000000  200.000000  200.000000  200.000000           200.000000\n",
       "mean    45.471887  -73.615784   60.395000    2.785459          4641.512253\n",
       "std      0.003728    0.011773   12.083419    0.944495          2664.131028\n",
       "min     45.464944  -73.635002   28.000000    0.000000             0.000000\n",
       "25%     45.468345  -73.625974   51.750000    2.639801          2340.691893\n",
       "50%     45.472427  -73.616678   63.000000    3.012348          4694.263953\n",
       "75%     45.475249  -73.605759   66.000000    3.251237          6979.636979\n",
       "max     45.477693  -73.595871   84.000000    6.635520          9006.744506"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ttrgpx)\n",
    "\n",
    "# reduce the size\n",
    "list_all_files_ReSample_as_df = [ttrgpx.fun_DownSample_gpx(x, number_of_sample = 200) for x in list_all_files_as_df]\n",
    "\n",
    "# check one gpx path\n",
    "list_all_files_ReSample_as_df[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8c21a-ee9d-4cc1-a7d2-0426fdf3debf",
   "metadata": {},
   "source": [
    "## Check last run date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ad120b-8685-4c74-acd0-0596579cee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDGRC_2024_09_16\n"
     ]
    }
   ],
   "source": [
    "head_tail = os.path.split(ll[-1])\n",
    "print(head_tail[1][0:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ac942-1864-48c3-9761-1c6ebe5653f7",
   "metadata": {},
   "source": [
    "# Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735060c4-763f-4236-8c92-74b9db4abe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ../data/csv/NDGRC*csv\n",
      "       0\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/csv/NDGRC*csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0dd6e-003e-40b4-a57e-c622708edcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../data/csv/NDGRC*csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a93389ea-7ebe-47a7-904e-e1ed14e94091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of gpx file name\n",
    "# -> list_all_files_gpx from above\n",
    "\n",
    "# create list of csv file name\n",
    "list_csv_file_name = [path_data_csv+os.path.split(x)[1][0:-4]+\"_downSample.csv\" for x in list_all_files_gpx]\n",
    "\n",
    "# export DataFrame as csv file\n",
    "for c,df_ in enumerate(list_all_files_ReSample_as_df):\n",
    "    df_.to_csv(list_csv_file_name[c], index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaddf45a-a945-4d01-9f59-18b0dfd253d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      54\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/csv/NDGRC*.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0270ba-68b0-41e1-a44c-33271338951a",
   "metadata": {},
   "source": [
    "Check that the csv files has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00f41667-581c-4b74-b1ea-b5847644ea6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-167.09175713996774"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load one file\n",
    "new_df = pd.read_csv(path_data_csv+\"NDGRC_2023_03_06_downSample.csv\")\n",
    "\n",
    "# to check if it is the same as the list of Dataframe\n",
    "new_df[\"cumulative_distance\"].iloc[-1] - list_all_files_ReSample_as_df[-1][\"cumulative_distance\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72127340-22ef-41d5-b320-926b9331edf7",
   "metadata": {},
   "source": [
    "Datavisualization in another notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
